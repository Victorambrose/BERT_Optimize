{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736eb2a9-2765-4e65-9fab-c81fa92bb6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc99e53971ec4e288652e24d17b456ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20bb0fa3140419b9d64893ac20ea02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f8411a96a449afbdbab135fe311456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20141f9d44414610be980015e69a5727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4c1d24290c454a985160db9ac1b4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e0daf32ac44ef181652d7e114cc372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45460888655c402794d57eb40435789b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac54c3dc0d245ae9e4d5b10d0b0e88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15830c0bd0b473fa469c02b54b82fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48dbbb1c5944700bcd8d7c48dbb4434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567e15fecf46419183ff6988d01d1b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5d607c45ca4204bd78702eae0a0a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c581ff1bfd1c460d96b9a366e7e9fcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49cf8afdc6847b98af047fbda811750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67836f91a01f42b4b11f0ee70eb39697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0424649eec343c5b2a13e9979840cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c203f5c309343aaa637c76af14a2eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30f0047e1bb40cf98ab1c53539ba480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.238406051671526\n",
      "Epoch 2, Loss: 0.6958643584570071\n",
      "Epoch 3, Loss: 0.46629333054087724\n",
      "Epoch 1, Loss: 1.450737627663155\n",
      "Epoch 2, Loss: 0.8909384776601571\n",
      "Epoch 3, Loss: 0.6953454813250005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legal-BERT Results: {'accuracy': 0.75, 'precision': 0.7436293084805153, 'recall': 0.75, 'f1': 0.7361039401937158}\n",
      "RoBERTa Results: {'accuracy': 0.6664285714285715, 'precision': 0.6709629188741265, 'recall': 0.6664285714285715, 'f1': 0.6456191849879634}\n",
      "Best performing model: Legal-BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.load_dataset(\"coastalcph/lex_glue\", \"scotus\")\n",
    "\n",
    "# Load legal dictionary from GitHub\n",
    "legal_dict_url = \"https://raw.githubusercontent.com/Victorambrose/BERT_Optimize/main/US_legal_dict.txt\"\n",
    "response = requests.get(legal_dict_url)\n",
    "legal_terms = set(response.text.splitlines())\n",
    "\n",
    "# Ensure necessary NLTK resources are downloaded\n",
    "nltk_data_path = os.path.expanduser(\"~/nltk_data\")  # Store in home directory\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "nltk.download('wordnet', download_dir=nltk_data_path)\n",
    "nltk.download('omw-1.4', download_dir=nltk_data_path)\n",
    "nltk.download('stopwords', download_dir=nltk_data_path)\n",
    "nltk.download('punkt', download_dir=nltk_data_path)\n",
    "nltk.download('averaged_perceptron_tagger', download_dir=nltk_data_path)\n",
    "nltk.download('maxent_ne_chunker', download_dir=nltk_data_path)\n",
    "nltk.download('words', download_dir=nltk_data_path)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize & lowercase\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))  # Load stopwords once\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words or word in legal_terms]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing safely\n",
    "dataset = dataset.map(lambda x: {\"text\": preprocess_text(x[\"text\"])} )\n",
    "\n",
    "# Tokenization\n",
    "tokenizer_legalbert = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer_legalbert(examples[\"text\"], truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define model class\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.fc(outputs.pooler_output)\n",
    "\n",
    "# Initialize models\n",
    "model_legalbert = TextClassifier(\"nlpaueb/legal-bert-base-uncased\", num_labels=13)\n",
    "model_roberta = TextClassifier(\"roberta-base\", num_labels=13)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, tokenizer, dataset, epochs=3, batch_size=8, lr=2e-5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        dataset[\"train\"][\"text\"], dataset[\"train\"][\"label\"], test_size=0.1, random_state=42)\n",
    "    \n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], torch.tensor(train_labels))\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_encodings[\"input_ids\"], val_encodings[\"attention_mask\"], torch.tensor(val_labels))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, tokenizer, dataset):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    test_texts, test_labels = dataset[\"test\"][\"text\"], dataset[\"test\"][\"label\"]\n",
    "    test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], torch.tensor(test_labels))\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8)\n",
    "    \n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Train and evaluate both models\n",
    "trained_legalbert = train_model(model_legalbert, tokenizer_legalbert, dataset)\n",
    "trained_roberta = train_model(model_roberta, tokenizer_roberta, dataset)\n",
    "\n",
    "legalbert_results = evaluate_model(trained_legalbert, tokenizer_legalbert, dataset)\n",
    "roberta_results = evaluate_model(trained_roberta, tokenizer_roberta, dataset)\n",
    "\n",
    "print(\"Legal-BERT Results:\", legalbert_results)\n",
    "print(\"RoBERTa Results:\", roberta_results)\n",
    "\n",
    "# Determine best model\n",
    "best_model = \"Legal-BERT\" if legalbert_results[\"accuracy\"] > roberta_results[\"accuracy\"] else \"RoBERTa\"\n",
    "print(f\"Best performing model: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94dfcb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 11:13:45.282723: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '3,4'\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6acdbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /raid/home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages/mask_rcnn-2.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (from nltk) (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acdc82c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ae5388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/local/nltk_data...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/usr/local/nltk_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usr/local/nltk_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Adjust path as needed\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopwords\u001b[39m\u001b[38;5;124m'\u001b[39m, download_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/usr/local/nltk_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m'\u001b[39m, download_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/usr/local/nltk_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordnet\u001b[39m\u001b[38;5;124m'\u001b[39m, download_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/usr/local/nltk_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tamil/lib/python3.12/site-packages/nltk/downloader.py:774\u001b[0m, in \u001b[0;36mDownloader.download\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(s, prefix2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    766\u001b[0m     print_to(\n\u001b[1;32m    767\u001b[0m         textwrap\u001b[38;5;241m.\u001b[39mfill(\n\u001b[1;32m    768\u001b[0m             s,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    771\u001b[0m         )\n\u001b[1;32m    772\u001b[0m     )\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincr_download(info_or_id, download_dir, force):\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;66;03m# Error messages\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, ErrorMessage):\n\u001b[1;32m    777\u001b[0m         show(msg\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/miniconda3/envs/tamil/lib/python3.12/site-packages/nltk/downloader.py:642\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[0;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m FinishCollectionMessage(info)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;66;03m# Handle Packages (delegate to a helper function).\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_package(info, download_dir, force)\n",
      "File \u001b[0;32m~/miniconda3/envs/tamil/lib/python3.12/site-packages/nltk/downloader.py:698\u001b[0m, in \u001b[0;36mDownloader._download_package\u001b[0;34m(self, info, download_dir, force)\u001b[0m\n\u001b[1;32m    695\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(filepath)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;66;03m# Ensure the download_dir exists\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(download_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    699\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_dir, info\u001b[38;5;241m.\u001b[39msubdir), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# Download the file.  This will raise an IOError if the url\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# is not found.\u001b[39;00m\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/usr/local/nltk_data'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"/usr/local/nltk_data\")  # Adjust path as needed\n",
    "\n",
    "nltk.download('stopwords', download_dir='/usr/local/nltk_data')\n",
    "nltk.download('punkt', download_dir='/usr/local/nltk_data')\n",
    "nltk.download('wordnet', download_dir='/usr/local/nltk_data')\n",
    "nltk.download('omw-1.4', download_dir='/usr/local/nltk_data')\n",
    "nltk.download('averaged_perceptron_tagger', download_dir='/usr/local/nltk_data')\n",
    "nltk.download('maxent_ne_chunker', download_dir='/usr/local/nltk_data')\n",
    "nltk.download('words', download_dir='/usr/local/nltk_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6a6b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"/usr/local/nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98e5c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /raid/home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages/mask_rcnn-2.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/srmist5/miniconda3/envs/tamil/lib/python3.12/site-packages (from nltk) (4.66.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a68fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/srmist5/nltk_data', '/home/srmist5/miniconda3/envs/tamil/nltk_data', '/home/srmist5/miniconda3/envs/tamil/share/nltk_data', '/home/srmist5/miniconda3/envs/tamil/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data', '/usr/local/nltk_data', '/usr/local/nltk_data', '/usr/local/nltk_data', '/usr/local/nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0826845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/srmist5/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d9a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/srmist5/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2025-03-28 15:05:05.828508: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec4781387134a2cbf2c504f2ed7674b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 2883 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3723 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4665 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8387 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10029 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1005 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6672 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5461 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3358 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3379 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4852 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5952 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 900 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1361 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3041 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3759 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1889 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 14003 to 14336 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2376 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1421 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3232 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3904 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7001 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5647 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4179 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2378 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2697 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2306 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4187 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2345 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2395 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5568 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6465 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4124 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2738 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1787 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1589 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6261 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1667 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2409 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5747 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1286 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3557 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1978 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2541 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 597 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2280 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7101 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6518 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 16085 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2479 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1914 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3242 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 544 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2092 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2573 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2906 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4392 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7784 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3346 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1586 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5321 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10307 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4693 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5869 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4777 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5336 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2288 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3589 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4379 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12972 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5195 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5047 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7157 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3617 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1918 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3823 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4065 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8290 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2169 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5980 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7331 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7986 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5158 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2867 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3493 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3501 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3722 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3900 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2273 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1093 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2394 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2181 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7809 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8040 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2018 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7817 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4323 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3762 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2571 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2891 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2265 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1501 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3751 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6634 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2791 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4282 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 11118 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1350 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12954 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2687 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6110 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3430 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1834 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1854 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2575 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8244 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2643 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3485 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4813 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1865 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12802 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4125 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8385 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5327 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3416 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2816 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4263 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5820 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 489 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10618 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2153 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8832 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2979 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 961 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3797 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1997 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3734 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5485 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4584 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 919 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2909 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1979 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2582 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1268 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4329 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5708 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3524 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1132 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3453 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5185 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1441 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3314 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 769 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1303 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 322 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6944 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4870 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1302 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 16322 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8485 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5541 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1901 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1423 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 999 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2365 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4260 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2163 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12077 to 12288 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3048 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2863 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1151 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2173 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2756 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2234 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 15519 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12201 to 12288 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1513 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 369 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4759 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2340 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9946 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3120 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2945 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8822 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2959 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3095 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3345 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6789 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1276 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3534 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 11056 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1706 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3967 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5360 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12388 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9348 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7630 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 832 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 15802 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6474 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8423 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3767 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4780 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2850 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7442 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6995 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12182 to 12288 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10986 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6137 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9148 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1960 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1577 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9420 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 517 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1928 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3318 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2889 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5160 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6885 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 546 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7437 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12605 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 11088 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4118 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8586 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4051 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 13986 to 14336 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4625 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5328 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3267 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5932 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9322 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 352 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2184 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6084 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1305 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7522 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10884 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 15499 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7127 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9695 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 740 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9031 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2668 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1398 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1762 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6576 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 440 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1007 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2651 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4529 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3676 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 14292 to 14336 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9078 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3132 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3502 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7355 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1595 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6794 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1644 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7625 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1267 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3573 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5662 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3086 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7050 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3768 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2642 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12739 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8550 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4223 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8016 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3097 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2821 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3843 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6921 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 536 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2751 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2455 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2581 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2474 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5097 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8022 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2502 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5458 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7583 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4913 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10450 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3622 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6447 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6627 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1154 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6022 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5140 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1339 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3520 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7210 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1885 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3032 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 643 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4185 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5555 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9847 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6335 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2740 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2410 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3094 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 414 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3598 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3571 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9357 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2027 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4970 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2123 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 912 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7770 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2368 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12243 to 12288 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5819 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 15736 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1451 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3669 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5862 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2937 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2098 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9013 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7207 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5254 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8830 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7046 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5095 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1729 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1633 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 15485 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2443 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1187 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6656 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8019 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1677 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3599 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3018 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4654 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2610 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1717 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2379 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6883 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7678 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9275 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2211 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1301 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5718 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5885 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1439 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3576 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2556 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2250 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2109 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 363 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1254 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1308 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2155 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1891 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4089 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3584 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2172 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2894 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3043 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1545 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2276 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5906 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3205 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3995 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4226 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2776 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2256 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 265 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5142 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1727 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 395 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8505 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1279 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5274 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3549 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3921 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2613 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4215 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 649 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4938 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2497 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2709 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2851 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3291 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4822 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5309 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2947 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2795 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8902 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7045 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6292 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1582 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3136 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1863 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2631 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 871 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5571 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3874 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4305 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5323 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12192 to 12288 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 584 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 446 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1607 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4031 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 360 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4443 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6938 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3559 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6723 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2124 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4511 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10794 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2679 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8883 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3718 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7277 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3648 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1604 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3155 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2216 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4797 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 11462 to 12288 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1610 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2842 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4576 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 717 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1125 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5374 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 455 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3033 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4318 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2147 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5049 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4540 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 519 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10873 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1650 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2501 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6922 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1080 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1895 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4405 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6042 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4845 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1082 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3264 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1436 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3746 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1639 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 615 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4856 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 792 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3269 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2682 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1220 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1124 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4436 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10605 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3212 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6242 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 872 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3422 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7189 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1770 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5340 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7227 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 812 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5122 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5677 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8206 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2145 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1581 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2703 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 548 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3021 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1347 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2762 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2831 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1883 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3829 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9411 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2892 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 982 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2282 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4466 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1873 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 893 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5127 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1494 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3780 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 539 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1813 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1392 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 290 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2274 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 618 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2037 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3560 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8691 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1691 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2677 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3343 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7469 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8935 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 113 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 454 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6032 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1576 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3045 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7609 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8135 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4712 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4159 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2760 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6444 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6030 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2852 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3945 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4200 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4648 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5467 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5525 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3316 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2565 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10924 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1235 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 437 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4241 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 959 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 980 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 148 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3131 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1774 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1552 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6822 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5873 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3690 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2183 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3392 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 913 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2050 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 461 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4839 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 878 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1535 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4640 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1811 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10112 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1179 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1848 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1259 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2432 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6397 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2004 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7640 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 579 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2509 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 720 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3069 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1887 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2107 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3479 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3154 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1246 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3006 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4357 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2348 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6914 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1648 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4199 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1825 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1139 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8968 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1587 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6665 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2666 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 14347 to 15360 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4216 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5552 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1823 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1253 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3737 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6158 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3530 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2023 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6477 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4238 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9632 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5365 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3323 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4033 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 232 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 633 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5314 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4497 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1532 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5353 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2716 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1911 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 16147 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6549 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4941 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1541 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7754 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5603 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2730 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1797 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4016 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 556 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 377 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 917 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1432 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1624 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1756 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2187 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2526 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1162 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4705 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2116 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 11797 to 12288 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 210 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1826 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3082 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1050 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 957 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2053 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 868 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1518 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 732 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3684 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1843 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3977 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2369 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2621 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5109 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8532 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4411 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9276 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3366 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1274 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3309 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2886 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2574 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2295 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5318 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1690 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1537 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4914 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 332 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1594 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3231 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3066 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4295 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 318 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1957 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6218 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4748 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4887 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1680 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3566 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2576 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2367 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3103 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2652 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4248 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1091 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4137 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4112 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7964 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2415 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1881 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7059 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8536 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2384 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1971 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4456 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2419 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3811 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 496 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 941 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5225 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3472 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4598 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9282 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1574 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9227 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1793 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1077 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4209 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4244 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4632 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1534 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 13467 to 14336 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7386 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1505 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2286 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2505 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2901 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1459 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 14311 to 14336 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6783 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3228 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5277 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3541 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2279 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 91 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5531 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8361 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 14909 to 15360 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6235 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4227 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 334 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 487 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12783 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 268 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 182 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2451 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2727 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1491 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2966 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 656 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1772 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1175 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3193 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 983 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4951 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8104 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6338 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5372 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 613 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5512 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6820 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3432 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3962 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3306 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2003 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 625 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1185 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1533 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2464 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 13520 to 14336 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1709 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8989 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4043 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5958 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7847 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 650 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3112 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1130 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1643 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 598 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2392 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7274 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2943 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3547 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9294 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 11201 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4531 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1855 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3711 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1463 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2363 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2354 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2125 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 755 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8128 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9244 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2390 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1732 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 894 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 139 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1775 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4083 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3478 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7072 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9594 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 317 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6731 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2552 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4795 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8461 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 287 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2456 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2308 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3173 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3487 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1800 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1202 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1514 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4857 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2221 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 910 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1483 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3310 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1166 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2982 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3513 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1038 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1204 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3920 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1131 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5876 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5449 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4893 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4888 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7545 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3336 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10422 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2710 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1269 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6143 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 560 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3491 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1910 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2441 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2648 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2503 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 892 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2540 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9567 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3092 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4969 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1890 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3588 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2315 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9180 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 323 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3079 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2296 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4684 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2711 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 866 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12325 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3570 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2764 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6889 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3170 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4752 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3288 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9947 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1329 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8338 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1661 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5667 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2135 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6939 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10235 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2230 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2022 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6678 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2327 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7234 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 374 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 300 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1656 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2530 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10584 to 11264 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1543 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 307 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5128 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1651 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4604 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1679 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 266 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1450 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4917 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1976 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1884 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4571 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6912 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5721 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2152 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7644 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 884 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3255 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3851 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2413 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2019 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 553 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4325 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1600 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2461 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2314 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5021 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2055 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1364 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2662 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1016 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 10213 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2333 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 658 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 951 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 719 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1322 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 349 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2837 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7230 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 540 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1075 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1530 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4431 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4729 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3894 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1354 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5378 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1757 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2201 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8230 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3047 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2520 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2893 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3933 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4145 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2836 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4532 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2598 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2495 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1802 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2907 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2888 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6796 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5074 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2785 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3457 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3407 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4439 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4359 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3315 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3686 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 16360 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3317 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6151 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2539 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5348 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2551 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2480 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1434 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4643 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9431 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6812 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1605 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5244 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1415 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4837 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6659 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2249 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4243 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1321 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2073 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4453 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5897 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 955 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1972 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2460 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2275 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4574 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5813 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3019 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2903 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3488 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 466 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6408 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1763 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 434 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1917 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 611 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7081 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 188 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3537 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4332 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 15477 to 16384 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 692 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3873 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1025 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5410 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3236 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4087 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5629 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1273 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3360 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 384 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3384 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2486 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1248 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6047 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5302 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3437 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6506 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3621 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7722 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4101 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 8545 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3062 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2732 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2693 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5199 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 623 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 14619 to 15360 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6478 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9418 to 10240 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 818 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1833 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2361 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2787 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9050 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1103 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5901 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3739 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7881 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3444 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1969 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 836 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5107 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3341 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2095 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6257 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 796 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6255 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 15322 to 15360 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 865 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3698 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1334 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 9034 to 9216 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 4164 to 5120 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1906 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 14958 to 15360 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6773 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6060 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 6472 to 7168 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 7635 to 8192 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 351 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 12861 to 13312 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 471 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 3625 to 4096 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 848 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1672 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 5577 to 6144 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 196 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 186 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 828 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 567 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1021 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1089 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 2383 to 3072 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1956 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 475 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report, roc_curve, auc\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.load_dataset(\"coastalcph/lex_glue\", \"scotus\")\n",
    "\n",
    "# Load legal dictionary from GitHub\n",
    "legal_dict_url = \"https://raw.githubusercontent.com/Victorambrose/BERT_Optimize/main/US_legal_dict.txt\"\n",
    "response = requests.get(legal_dict_url)\n",
    "legal_terms = set(response.text.splitlines())\n",
    "\n",
    "# Load abbreviation mapping safely\n",
    "abbr_dict_url = \"https://raw.githubusercontent.com/Victorambrose/BERT_Optimize/main/legal_abbr.txt\"\n",
    "response = requests.get(abbr_dict_url)\n",
    "\n",
    "# Process lines carefully to avoid errors\n",
    "abbr_dict = {}\n",
    "for line in response.text.splitlines():\n",
    "    if \"=\" in line:  # Ensure valid format\n",
    "        key, value = line.split(\"=\", 1)  # Split only at the first \"=\"\n",
    "        abbr_dict[key.strip()] = value.strip()  # Remove any extra spaces\n",
    "\n",
    "\n",
    "# Ensure necessary NLTK resources are downloaded\n",
    "nltk_data_path = os.path.expanduser(\"~/nltk_data\")\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "nltk.download('wordnet', download_dir=nltk_data_path)\n",
    "nltk.download('stopwords', download_dir=nltk_data_path)\n",
    "nltk.download('punkt', download_dir=nltk_data_path)\n",
    "\n",
    "# Load summarization model\n",
    "summarizer = AutoModelForSeq2SeqLM.from_pretrained(\"nsi319/legal-led-base-16384\")\n",
    "summarizer_tokenizer = AutoTokenizer.from_pretrained(\"nsi319/legal-led-base-16384\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\\\s+', ' ', text)  # Remove extra spaces\n",
    "    for abbr, full_form in abbr_dict.items():\n",
    "        text = text.replace(abbr, full_form)  # Replace abbreviations\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize & lowercase\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))  # Load stopwords once\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words or word in legal_terms]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def summarize_text(text):\n",
    "    inputs = summarizer_tokenizer(text, return_tensors=\"pt\", max_length=16384, truncation=True)\n",
    "    summary_ids = summarizer.generate(**inputs)\n",
    "    return summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Apply preprocessing and summarization\n",
    "dataset = dataset.map(lambda x: {\"text\": summarize_text(preprocess_text(x[\"text\"]))})\n",
    "\n",
    "# Tokenization\n",
    "tokenizer_legalbert = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer_legalbert(examples[\"text\"], truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define model class\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.fc(outputs.pooler_output)\n",
    "\n",
    "# Initialize models\n",
    "model_legalbert = TextClassifier(\"nlpaueb/legal-bert-base-uncased\", num_labels=13)\n",
    "model_roberta = TextClassifier(\"roberta-base\", num_labels=13)\n",
    "\n",
    "def train_model(model, tokenizer, dataset, epochs=3, batch_size=8, lr=2e-5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        dataset[\"train\"][\"text\"], dataset[\"train\"][\"label\"], test_size=0.1, random_state=42)\n",
    "    \n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], torch.tensor(train_labels))\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_encodings[\"input_ids\"], val_encodings[\"attention_mask\"], torch.tensor(val_labels))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "    return model\n",
    "\n",
    "def plot_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    plt.plot(fpr, tpr, label='ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, tokenizer, dataset):\n",
    "    test_texts, test_labels = dataset[\"test\"][\"text\"], dataset[\"test\"][\"label\"]\n",
    "    test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    model.eval()\n",
    "    predictions = torch.argmax(model(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"]), dim=1)\n",
    "    plot_metrics(test_labels, predictions.cpu().numpy())\n",
    "\n",
    "trained_legalbert = train_model(model_legalbert, tokenizer_legalbert, dataset)\n",
    "evaluate_model(trained_legalbert, tokenizer_legalbert, dataset)\n",
    "\n",
    "random_sample = random.choice(dataset[\"test\"][\"text\"])\n",
    "print(\"Random Sample Input:\", random_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504b5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d2d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tamil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
