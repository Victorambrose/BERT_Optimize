{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.load_dataset(\"coastalcph/lex_glue\", \"scotus\")\n",
    "\n",
    "\n",
    "tokenizer_legalbert = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "tokenizer_roberta = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer_legalbert(examples[\"text\"], truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Define model class\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.fc(outputs.pooler_output)\n",
    "\n",
    "# Initialize models\n",
    "model_legalbert = TextClassifier(\"nlpaueb/legal-bert-base-uncased\", num_labels=13)\n",
    "model_roberta = TextClassifier(\"roberta-base\", num_labels=13)\n",
    "\n",
    "# Initialize metrics storage\n",
    "metrics_data = []\n",
    "\n",
    "def train_model(model, tokenizer, dataset, model_name, epochs=3, batch_size=8, lr=2e-5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        dataset[\"train\"][\"text\"], dataset[\"train\"][\"label\"], test_size=0.1, random_state=42)\n",
    "    \n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    \n",
    "    train_dataset = torch.utils.data.TensorDataset(train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], torch.tensor(train_labels))\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_encodings[\"input_ids\"], val_encodings[\"attention_mask\"], torch.tensor(val_labels))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_data.append({\"Model\": model_name, \"Epoch\": epoch+1, \"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1\": f1})\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader)}, Accuracy = {accuracy:.4f}, Precision = {precision:.4f}, Recall = {recall:.4f}, F1 = {f1:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train models and collect metrics\n",
    "trained_legalbert = train_model(model_legalbert, tokenizer_legalbert, dataset, \"legal-bert-base-uncased\")\n",
    "trained_roberta = train_model(model_roberta, tokenizer_roberta, dataset, \"roberta-base\")\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot Accuracy per epoch\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(data=metrics_df, x=\"Epoch\", y=\"Accuracy\", hue=\"Model\", marker=\"o\")\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision, Recall, and F1-score\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.lineplot(data=metrics_df, x=\"Epoch\", y=\"Precision\", hue=\"Model\", marker=\"o\", ax=axes[0])\n",
    "axes[0].set_title(\"Precision per Epoch\")\n",
    "sns.lineplot(data=metrics_df, x=\"Epoch\", y=\"Recall\", hue=\"Model\", marker=\"o\", ax=axes[1])\n",
    "axes[1].set_title(\"Recall per Epoch\")\n",
    "sns.lineplot(data=metrics_df, x=\"Epoch\", y=\"F1\", hue=\"Model\", marker=\"o\", ax=axes[2])\n",
    "axes[2].set_title(\"F1 Score per Epoch\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
